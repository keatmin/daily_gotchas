"use strict";(self.webpackChunkgotchas=self.webpackChunkgotchas||[]).push([[1944],{3905:function(e,t,n){n.d(t,{Zo:function(){return p},kt:function(){return u}});var a=n(7294);function r(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function o(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);t&&(a=a.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,a)}return n}function i(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?o(Object(n),!0).forEach((function(t){r(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):o(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function s(e,t){if(null==e)return{};var n,a,r=function(e,t){if(null==e)return{};var n,a,r={},o=Object.keys(e);for(a=0;a<o.length;a++)n=o[a],t.indexOf(n)>=0||(r[n]=e[n]);return r}(e,t);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(a=0;a<o.length;a++)n=o[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(r[n]=e[n])}return r}var l=a.createContext({}),c=function(e){var t=a.useContext(l),n=t;return e&&(n="function"==typeof e?e(t):i(i({},t),e)),n},p=function(e){var t=c(e.components);return a.createElement(l.Provider,{value:t},e.children)},d={inlineCode:"code",wrapper:function(e){var t=e.children;return a.createElement(a.Fragment,{},t)}},m=a.forwardRef((function(e,t){var n=e.components,r=e.mdxType,o=e.originalType,l=e.parentName,p=s(e,["components","mdxType","originalType","parentName"]),m=c(n),u=r,h=m["".concat(l,".").concat(u)]||m[u]||d[u]||o;return n?a.createElement(h,i(i({ref:t},p),{},{components:n})):a.createElement(h,i({ref:t},p))}));function u(e,t){var n=arguments,r=t&&t.mdxType;if("string"==typeof e||r){var o=n.length,i=new Array(o);i[0]=m;var s={};for(var l in t)hasOwnProperty.call(t,l)&&(s[l]=t[l]);s.originalType=e,s.mdxType="string"==typeof e?e:r,i[1]=s;for(var c=2;c<o;c++)i[c]=n[c];return a.createElement.apply(null,i)}return a.createElement.apply(null,n)}m.displayName="MDXCreateElement"},101:function(e,t,n){n.r(t),n.d(t,{frontMatter:function(){return s},contentTitle:function(){return l},metadata:function(){return c},assets:function(){return p},toc:function(){return d},default:function(){return u}});var a=n(7462),r=n(3366),o=(n(7294),n(3905)),i=["components"],s={slug:"python-memory-management",title:"Managing Python Memory",authors:"keatmin",tags:["python","memory"]},l=void 0,c={permalink:"/daily_gotchas/gotchas/python-memory-management",source:"@site/gotchas/2021-09-06-python-memory.md",title:"Managing Python Memory",description:"Memory management in Python is interesting as compared to low-level languages since it is being managed automatically. This gotchas will explain how to use less memory when managing data that is relatively big in a function.",date:"2021-09-06T00:00:00.000Z",formattedDate:"September 6, 2021",tags:[{label:"python",permalink:"/daily_gotchas/gotchas/tags/python"},{label:"memory",permalink:"/daily_gotchas/gotchas/tags/memory"}],readingTime:2.355,truncated:!1,authors:[{name:"keatmin",title:"Data nerd",url:"https://github.com/keatmin",imageURL:"https://github.com/keatmin.png",key:"keatmin"}],prevItem:{title:"Mechanism in async",permalink:"/daily_gotchas/gotchas/async-mechanism"},nextItem:{title:"AIOHttp Client Settings",permalink:"/daily_gotchas/gotchas/aiohttp-client-settings"}},p={authorsImageUrls:[void 0]},d=[{value:"Data Scientist example",id:"data-scientist-example",children:[{value:"Solutions",id:"solutions",children:[]}]},{value:"Conclusion",id:"conclusion",children:[]}],m={toc:d};function u(e){var t=e.components,n=(0,r.Z)(e,i);return(0,o.kt)("wrapper",(0,a.Z)({},m,n,{components:t,mdxType:"MDXLayout"}),(0,o.kt)("p",null,"Memory management in Python is interesting as compared to low-level languages since it is being managed automatically. This gotchas will explain how to use less memory when managing data that is relatively big in a function. "),(0,o.kt)("p",null,"The way Python knows when to release the memory of an object depends on the counter. In short, it tracks objects and frees it when they're no longer used. Take this example:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},'\ndef foo():\n    data: dict = {"john": "wick"}\n    bar(data)\n    return\n\ndef bar(d):\n    print(d)\n    return\n')),(0,o.kt)("p",null,"When ",(0,o.kt)("inlineCode",{parentName:"p"},"foo()")," is called the counter looks like this:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},'foo():\n    data = {"john": "wick"} # Data object counter increased to 1\n    bar(d=data) # d reference counter increased to 2\n    print(d)\n    return # d goes away and released, counter back to 1\nreturn # data goes away and it goes back to 0\n# Dictionary released and freed\n')),(0,o.kt)("div",{className:"admonition admonition-note alert alert--secondary"},(0,o.kt)("div",{parentName:"div",className:"admonition-heading"},(0,o.kt)("h5",{parentName:"div"},(0,o.kt)("span",{parentName:"h5",className:"admonition-icon"},(0,o.kt)("svg",{parentName:"span",xmlns:"http://www.w3.org/2000/svg",width:"14",height:"16",viewBox:"0 0 14 16"},(0,o.kt)("path",{parentName:"svg",fillRule:"evenodd",d:"M6.3 5.69a.942.942 0 0 1-.28-.7c0-.28.09-.52.28-.7.19-.18.42-.28.7-.28.28 0 .52.09.7.28.18.19.28.42.28.7 0 .28-.09.52-.28.7a1 1 0 0 1-.7.3c-.28 0-.52-.11-.7-.3zM8 7.99c-.02-.25-.11-.48-.31-.69-.2-.19-.42-.3-.69-.31H6c-.27.02-.48.13-.69.31-.2.2-.3.44-.31.69h1v3c.02.27.11.5.31.69.2.2.42.31.69.31h1c.27 0 .48-.11.69-.31.2-.19.3-.42.31-.69H8V7.98v.01zM7 2.3c-3.14 0-5.7 2.54-5.7 5.68 0 3.14 2.56 5.7 5.7 5.7s5.7-2.55 5.7-5.7c0-3.15-2.56-5.69-5.7-5.69v.01zM7 .98c3.86 0 7 3.14 7 7s-3.14 7-7 7-7-3.12-7-7 3.14-7 7-7z"}))),"note")),(0,o.kt)("div",{parentName:"div",className:"admonition-content"},(0,o.kt)("p",{parentName:"div"},"The ",(0,o.kt)("inlineCode",{parentName:"p"},"print()")," function prints the data, it does nothing to change the counter\nThe ",(0,o.kt)("inlineCode",{parentName:"p"},"bar()")," returns decreased the counter"))),(0,o.kt)("p",null,"The issue with this is once the data is passed to ",(0,o.kt)("inlineCode",{parentName:"p"},"bar()")," the dictionary was not used by ",(0,o.kt)("inlineCode",{parentName:"p"},"foo()")," and yet the memory persists in ",(0,o.kt)("inlineCode",{parentName:"p"},"foo()")," until ",(0,o.kt)("inlineCode",{parentName:"p"},"foo()")," exits even though it is not being used by ",(0,o.kt)("inlineCode",{parentName:"p"},"foo()"),". In practice it is not that bad to do that, however, if the object is a big numpy array that takes up 1GB of memory, this will create redundancy of an extra 1GB in memory"),(0,o.kt)("h2",{id:"data-scientist-example"},"Data Scientist example"),(0,o.kt)("p",null,"It is very common for data scientist to do something like this:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},"import pandas as pd\n\ndef load_data(data_path: str):\n    return pd.read_csv(data_path) # Huge data\n\ndef process_data(data_path: str):\n    data = load_data(data_path)\n    return transform_1(transform_2(data))\n\ndef transform_1(data):\n    return data * 2\n\ndef transform_2(data):\n    return data + 10\n\nprocess_data()\n")),(0,o.kt)("p",null,"Looks benign, but if we were take a close look into it. ",(0,o.kt)("inlineCode",{parentName:"p"},"data")," in ",(0,o.kt)("inlineCode",{parentName:"p"},"process_data()")," persists while ",(0,o.kt)("inlineCode",{parentName:"p"},"transform_1")," and ",(0,o.kt)("inlineCode",{parentName:"p"},"transform_2")," is running. The peak usage of data will be 3x of the data size from ",(0,o.kt)("inlineCode",{parentName:"p"},"load_data")," because a brief moment of original data is present when transformation is happening. "),(0,o.kt)("p",null,"At peak:"),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},"1x from data persisting"),(0,o.kt)("li",{parentName:"ul"},"2x from transform1 and transform2")),(0,o.kt)("p",null,"The maximum for peak memory from these should be 2x rather than 3x, the extra 1x came from the ",(0,o.kt)("inlineCode",{parentName:"p"},"data")," in process_data() persisted until the end of the function!"),(0,o.kt)("h3",{id:"solutions"},"Solutions"),(0,o.kt)("h4",{id:"solution-1"},"Solution #1"),(0,o.kt)("p",null,"Don't define a short lived variable"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},"def process_data(data_path):\n    return transform2(transform1(load_data(data_path)))\n")),(0,o.kt)("h4",{id:"solution-2"},"Solution #2"),(0,o.kt)("p",null,"Mutate locally or replace data"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},"def process_data(data_path):\n    data = load_data(data_path)\n    data = transform1(data)\n    data = transform2(data)\n    return data\n")),(0,o.kt)("h2",{id:"conclusion"},"Conclusion"),(0,o.kt)("p",null,"It is fine to let an object live a little longer as most of the time it's quite negligible, however when dealing with larger data, living longer can cause OOM or require a higher memory to run a function like such."),(0,o.kt)("p",null,"Get into habit of tracking your objects' references"),(0,o.kt)("p",null,"Link: ",(0,o.kt)("a",{parentName:"p",href:"https://pythonspeed.com/articles/function-calls-prevent-garbage-collection/"},"Pythonspeed")))}u.isMDXComponent=!0}}]);